{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement"
      ],
      "metadata": {
        "id": "9EaJ8AGwpM-2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVpfFjWHXk8l"
      },
      "source": [
        "### Business context\n",
        "\n",
        "Employee Promotion means the ascension of an employee to higher ranks, this aspect of the job is what drives employees the most. The ultimate reward for dedication and loyalty towards an organization and the HR team plays an important role in handling all these promotion tasks based on ratings and other attributes available.\n",
        "\n",
        "The HR team in JMD company stored data on the promotion cycle last year, which consists of details of all the employees in the company working last year and also if they got promoted or not, but every time this process gets delayed due to so many details available for each employee - it gets difficult to compare and decide.\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "For the upcoming appraisal cycle, the HR team wants to utilize the stored data and leverage machine learning to make a model that will predict if a person is eligible for promotion or not. You, as a data scientist at JMD company, need to come up with the best possible model that will help the HR team to predict if a person is eligible for promotion or not.\n",
        "\n",
        "\n",
        "### Data Description\n",
        "\n",
        "- employee_id: Unique ID for the employee\n",
        "- department: Department of employee\n",
        "- region: Region of employment (unordered)\n",
        "- education: Education Level\n",
        "- gender: Gender of Employee\n",
        "- recruitment_channel: Channel of recruitment for employee\n",
        "- no_ of_ trainings: no of other training completed in the previous year on soft skills, technical skills, etc.\n",
        "- age: Age of Employee\n",
        "- previous_ year_ rating: Employee Rating for the previous year\n",
        "- length_ of_ service: Length of service in years\n",
        "- awards_ won: if awards won during the previous year then 1 else 0\n",
        "- avg_ training_ score: Average score in current training evaluations\n",
        "- is_promoted: (Target) Recommended for promotion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbHOIdlwcrqR"
      },
      "source": [
        "## **Please read the instructions carefully before starting the project.**\n",
        "This is a commented Jupyter IPython Notebook file in which all the instructions and tasks to be performed are mentioned.\n",
        "* Blanks '_______' are provided in the notebook that\n",
        "needs to be filled with an appropriate code to get the correct result. With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space.\n",
        "* Identify the task to be performed correctly, and only then proceed to write the required code.\n",
        "* Fill the code wherever asked by the commented lines like \"# write your code here\" or \"# complete the code\". Running incomplete code may throw error.\n",
        "* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors.\n",
        "* Add the results/observations (wherever mentioned) derived from the analysis in the presentation and submit the same.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_-uuGqH-qTt"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the libraries with the specified version.\n",
        "# uncomment and run the following line if Google Colab is being used\n",
        "# !pip install scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==1.5.3 imbalanced-learn==0.10.1 xgboost==2.0.3 -q --user"
      ],
      "metadata": {
        "id": "cMvBdEOVjkPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the libraries with the specified version.\n",
        "# uncomment and run the following lines if Jupyter Notebook is being used\n",
        "# !pip install scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.25.2 pandas==1.5.3 imbalanced-learn==0.10.1 xgboost==2.0.3 -q --user\n",
        "# !pip install --upgrade -q threadpoolctl"
      ],
      "metadata": {
        "id": "DeyJVznuk3AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zqzTgQ8Xk8n"
      },
      "outputs": [],
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# To tune model, get different metric scores, and split data\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "\n",
        "# To be used for data scaling and one hot encoding\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# To oversample and undersample data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# To do hyperparameter tuning\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# To impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# To define maximum number of columns to be displayed in a dataframe\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "# To supress scientific notations for a dataframe\n",
        "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
        "\n",
        "# To help with model building\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    AdaBoostClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    RandomForestClassifier,\n",
        "    BaggingClassifier,\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# To suppress scientific notations\n",
        "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
        "\n",
        "# To supress warnings\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxhpZv9y-qTw"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWp-4FiQXk8p"
      },
      "outputs": [],
      "source": [
        "promotion = pd.read_csv(\"employee_promotion.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1TEog7cAs5m"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-5jUOgu-qTz"
      },
      "source": [
        "The initial steps to get an overview of any dataset is to:\n",
        "- observe the first few rows of the dataset, to check whether the dataset has been loaded properly or not\n",
        "- get information about the number of rows and columns in the dataset\n",
        "- find out the data types of the columns to ensure that data is stored in the preferred format and the value of each property is as expected.\n",
        "- check the statistical summary of the dataset to get an overview of the numerical columns of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQi5ygTC-qT1"
      },
      "source": [
        "### Checking the shape of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y8epHpjbp0z"
      },
      "source": [
        "# Checking the number of rows and columns in the training data\n",
        "promotion.'_______' ##  Complete the code to view dimensions of the train data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUJ_jcB1Xk8q"
      },
      "outputs": [],
      "source": [
        "# let's create a copy of the data\n",
        "data = promotion.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "961px703qhLV"
      },
      "source": [
        "### Displaying the first few rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9RnN7Twbp03"
      },
      "source": [
        "# let's view the first 5 rows of the data\n",
        "data.'_______' ##  Complete the code to view top 5 rows of the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9Ir8YPgbp04"
      },
      "source": [
        "# let's view the last 5 rows of the data\n",
        "data.'_______' ##  Complete the code to view last 5 rows of the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TcqcxbK-qT3"
      },
      "source": [
        "### Checking the data types of the columns for the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXBYJoKkbp04"
      },
      "source": [
        "# let's check the data types of the columns in the dataset\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNr4bWoM-qT5"
      },
      "source": [
        "### Checking for duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0EmBHNmbp04"
      },
      "source": [
        "# let's check for duplicate values in the data\n",
        "data.'_______' ##  Complete the code to check duplicate entries in the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch_TjRfF-qT5"
      },
      "source": [
        "### Checking for missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlwFZm-Jbp05"
      },
      "source": [
        "# let's check for missing values in the data\n",
        "data.'_______' ##  Complete the code to check missing entries in the train data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUCorhch-qT4"
      },
      "source": [
        "### Statistical summary of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6lzvHKCbp06"
      },
      "source": [
        "# let's view the statistical summary of the numerical columns in the data\n",
        "data.'_______' ##  Complete the code to print the statitical summary of the train data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mxs0OnMXk8s"
      },
      "outputs": [],
      "source": [
        "# let's view the statistical summary of the numerical columns in the data\n",
        "data.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuM4uU3BXk8s"
      },
      "source": [
        "**Let's check the number of unique values in each column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt1Rad3PXk8t"
      },
      "outputs": [],
      "source": [
        "data.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70PypqARXk8t"
      },
      "outputs": [],
      "source": [
        "for i in data.describe(include=[\"object\"]).columns:\n",
        "    print(\"Unique values in\", i, \"are :\")\n",
        "    print(data[i].value_counts())\n",
        "    print(\"*\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-d5-EseXk8t"
      },
      "outputs": [],
      "source": [
        "# ID column consists of uniques ID for clients and hence will not add value to the modeling\n",
        "data.drop(columns=\"employee_id\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGj5ULSEXk8s"
      },
      "outputs": [],
      "source": [
        "data[\"is_promoted\"].value_counts(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhPuzWO7hmV8"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YyWJgFlKlWM"
      },
      "source": [
        "#### The below functions need to be defined to carry out the Exploratory Data Analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIP4bI3Zbp07"
      },
      "source": [
        "# function to plot a boxplot and a histogram along the same scale.\n",
        "\n",
        "\n",
        "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a triangle will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5021de33"
      },
      "outputs": [],
      "source": [
        "# function to create labeled barplots\n",
        "\n",
        "\n",
        "def labeled_barplot(data, feature, perc=False, n=None):\n",
        "    \"\"\"\n",
        "    Barplot with percentage at the top\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    perc: whether to display percentages instead of count (default is False)\n",
        "    n: displays the top n category levels (default is None, i.e., display all levels)\n",
        "    \"\"\"\n",
        "\n",
        "    total = len(data[feature])  # length of the column\n",
        "    count = data[feature].nunique()\n",
        "    if n is None:\n",
        "        plt.figure(figsize=(count + 1, 5))\n",
        "    else:\n",
        "        plt.figure(figsize=(n + 1, 5))\n",
        "\n",
        "    plt.xticks(rotation=90, fontsize=15)\n",
        "    ax = sns.countplot(\n",
        "        data=data,\n",
        "        x=feature,\n",
        "        palette=\"Paired\",\n",
        "        order=data[feature].value_counts().index[:n].sort_values(),\n",
        "    )\n",
        "\n",
        "    for p in ax.patches:\n",
        "        if perc == True:\n",
        "            label = \"{:.1f}%\".format(\n",
        "                100 * p.get_height() / total\n",
        "            )  # percentage of each class of the category\n",
        "        else:\n",
        "            label = p.get_height()  # count of each level of the category\n",
        "\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height()  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the percentage\n",
        "\n",
        "    plt.show()  # show the plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c08fe5b8"
      },
      "outputs": [],
      "source": [
        "# function to plot stacked bar chart\n",
        "\n",
        "def stacked_barplot(data, predictor, target):\n",
        "    \"\"\"\n",
        "    Print the category counts and plot a stacked bar chart\n",
        "\n",
        "    data: dataframe\n",
        "    predictor: independent variable\n",
        "    target: target variable\n",
        "    \"\"\"\n",
        "    count = data[predictor].nunique()\n",
        "    sorter = data[target].value_counts().index[-1]\n",
        "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
        "        by=sorter, ascending=False\n",
        "    )\n",
        "    print(tab1)\n",
        "    print(\"-\" * 120)\n",
        "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
        "        by=sorter, ascending=False\n",
        "    )\n",
        "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 1, 5))\n",
        "    plt.legend(\n",
        "        loc=\"lower left\", frameon=False,\n",
        "    )\n",
        "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e90985c5"
      },
      "outputs": [],
      "source": [
        "### Function to plot distributions\n",
        "\n",
        "def distribution_plot_wrt_target(data, predictor, target):\n",
        "\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    target_uniq = data[target].unique()\n",
        "\n",
        "    axs[0, 0].set_title(\"Distribution of target for target=\" + str(target_uniq[0]))\n",
        "    sns.histplot(\n",
        "        data=data[data[target] == target_uniq[0]],\n",
        "        x=predictor,\n",
        "        kde=True,\n",
        "        ax=axs[0, 0],\n",
        "        color=\"teal\",\n",
        "    )\n",
        "\n",
        "    axs[0, 1].set_title(\"Distribution of target for target=\" + str(target_uniq[1]))\n",
        "    sns.histplot(\n",
        "        data=data[data[target] == target_uniq[1]],\n",
        "        x=predictor,\n",
        "        kde=True,\n",
        "        ax=axs[0, 1],\n",
        "        color=\"orange\",\n",
        "    )\n",
        "\n",
        "    axs[1, 0].set_title(\"Boxplot w.r.t target\")\n",
        "    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\"gist_rainbow\")\n",
        "\n",
        "    axs[1, 1].set_title(\"Boxplot (without outliers) w.r.t target\")\n",
        "    sns.boxplot(\n",
        "        data=data,\n",
        "        x=target,\n",
        "        y=predictor,\n",
        "        ax=axs[1, 1],\n",
        "        showfliers=False,\n",
        "        palette=\"gist_rainbow\",\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate analysis"
      ],
      "metadata": {
        "id": "kMZ-iAFSvY3s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RJVJyMaXk8u"
      },
      "source": [
        "#### Observations on No. of Trainings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9QPhoecXk8u"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot(data, \"no_of_trainings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's see the distribution of age of employee**"
      ],
      "metadata": {
        "id": "t6f6vtxUu7Pd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0svWVo63Xk8v"
      },
      "source": [
        "#### Observations on Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urRzHX-sXk8v"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'age'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQqeDcohXk8v"
      },
      "source": [
        "#### Observations on Length of Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgXu_fb7Xk8v"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'length_of_service'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's see the distribution of average training score of employee**"
      ],
      "metadata": {
        "id": "muhT-LxKuwH4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-1GJtmpXk8w"
      },
      "source": [
        "#### Observations on Average Training Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgbwy-pjXk8w"
      },
      "outputs": [],
      "source": [
        "histogram_boxplot('_______')  ## Complete the code to create histogram_boxplot for 'avg_training_score'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bEfcnKyXk8w"
      },
      "source": [
        "#### Observations on Department"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jJO0vXoXk8w"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(data, \"department\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsMA-L_SXk8x"
      },
      "source": [
        "#### Observations on Education"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0O9NSytXk8x"
      },
      "outputs": [],
      "source": [
        "labeled_barplot(data, \"education\")\n",
        "labeled_barplot('_______') ## Complete the code to create labeled_barplot for 'education'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCI5jLAyXk8x"
      },
      "source": [
        "#### Observations on Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIvOVXmoXk8x"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('_______') ## Complete the code to create labeled_barplot for 'gender'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "375LIJSqXk8x"
      },
      "source": [
        "#### Observations on Recruitment Channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M939SElvXk8y"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('_______') ## Complete the code to create labeled_barplot for 'recruitment_channel'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi2h9-R_Xk8y"
      },
      "source": [
        "#### Observations on Previous Year Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n009IIIXk8y"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('_______') ## Complete the code to create labeled_barplot for 'previous_year_rating'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw6XLeL1Xk8y"
      },
      "source": [
        "#### Observations on Awards Won"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8eUN6rkXk8y"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('_______') ## Complete the code to create labeled_barplot for 'awards_won'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo_TjLtrXk8z"
      },
      "source": [
        "#### Observations on Region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGPnv9dvXk8z"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('_______') ## Complete the code to create labeled_barplot for 'region'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-Og-a_qXk8z"
      },
      "source": [
        "#### Observations on target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRCRiR-VXk8z"
      },
      "outputs": [],
      "source": [
        "labeled_barplot('_______') ## Complete the code to create labeled_barplot for 'is_promoted'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaPBvS4FXk80"
      },
      "source": [
        "### Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qgbWPGmXk80"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data, hue=\"is_promoted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlAnw_xDXk81"
      },
      "source": [
        "#### Target variable vs Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIg0XO6rXk81"
      },
      "outputs": [],
      "source": [
        "distribution_plot_wrt_target(data, \"age\", \"is_promoted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's see the change in length of service (length_of_service) vary by the employee's promotion status (is_promoted)?**"
      ],
      "metadata": {
        "id": "IHDAuPmKvm4p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ruq7LujXk81"
      },
      "source": [
        "#### Target variable vs Length of Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iS4CT3TXk82"
      },
      "outputs": [],
      "source": [
        "distribution_plot_wrt_target(data, \"_____\", \"_____\") ## Complete the code to create distribution_plot for length_of_service vs is_promoted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejNtzzp-Xk82"
      },
      "source": [
        "#### Target variable vs Average Training Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbV7raI_Xk82"
      },
      "outputs": [],
      "source": [
        "distribution_plot_wrt_target(data, \"_____\", \"_____\") ## Complete the code to create distribution_plot for avg_training_score vs is_promoted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBq-u2UfXk82"
      },
      "source": [
        "#### Target variable vs Department"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGUFPAcdXk83"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(data, \"department\", \"is_promoted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyj-sWOgXk83"
      },
      "source": [
        "#### Target variable vs Region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CBHRReDXk83"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(data, \"region\", \"is_promoted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEMG1_lkXk83"
      },
      "source": [
        "#### Target variable vs Education"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjEehRG2Xk83"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(data,\"_____\", \"_____\") ## Complete the code to create distribution_plot for education vs is_promoted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvfrLMXYXk84"
      },
      "source": [
        "#### Target variable vs Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgUzHyjtXk84"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(data,\"_____\", \"_____\") ## Complete the code to create distribution_plot for gender vs is_promoted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhMfzOGkXk84"
      },
      "source": [
        "#### Target variable vs Recruitment Channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuMhrlz_Xk84"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(data,\"_____\", \"_____\") ## Complete the code to create distribution_plot for recruitment_channel vs is_promoted"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's see the previous rating(previous_year_rating) vary by the employee's promotion status (is_promoted)**"
      ],
      "metadata": {
        "id": "XshZPje-v4ly"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3V9J6ueXk84"
      },
      "source": [
        "#### Target variable vs Previous Year Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsiITxLBXk84"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(data,\"_____\", \"_____\") ## Complete the code to create distribution_plot for previous_year_rating vs is_promoted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C16v3j98Xk85"
      },
      "source": [
        "#### Target variable vs Awards Won"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjqJGI9fXk85"
      },
      "outputs": [],
      "source": [
        "stacked_barplot(data,\"_____\", \"_____\") ## Complete the code to create distribution_plot for awards_won vs is_promoted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLYLrkAyXk85"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data=data, x=\"awards_won\", y=\"avg_training_score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's see the attributes that have a strong correlation with each other**"
      ],
      "metadata": {
        "id": "ycn9O8SswBtz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NirFCSQcXk85"
      },
      "source": [
        "### Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtq8qhU2Xk86"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 7))\n",
        "sns.heatmap(data.corr(), annot=True, vmin=-1, vmax=1, fmt=\".2f\", cmap=\"Spectral\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "QHo0SRqVp9yG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEKBXLhOXk86"
      },
      "outputs": [],
      "source": [
        "data1 = data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split"
      ],
      "metadata": {
        "id": "rAiIh-pRqcIt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YceN97ZsXk86"
      },
      "outputs": [],
      "source": [
        "X = data1.drop([\"is_promoted\"], axis=1)\n",
        "y = data1[\"is_promoted\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ul3cehKXk86"
      },
      "outputs": [],
      "source": [
        "# Splitting data into training and validation set:\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split('_______') ## Complete the code to split the data into train test in the ratio 80:20\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split('_______') ## Complete the code to split the data into train test in the ratio 75:25\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "081ec1f8"
      },
      "source": [
        "### Missing value imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEtnRjiEXk86"
      },
      "outputs": [],
      "source": [
        "# Defining the imputers for numerical and categorical variables\n",
        "imputer_mode = SimpleImputer(strategy=\"most_frequent\")\n",
        "imputer_median = SimpleImputer(strategy=\"median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spw_aqAnXk87"
      },
      "outputs": [],
      "source": [
        "# Fit and transform the train data\n",
        "X_train[[\"education\"]] = imputer_mode.fit_transform(X_train[[\"education\"]])\n",
        "\n",
        "# Transform the validation data\n",
        "X_val[[\"education\"]]  =  '_______' ## Complete the code to impute missing values in X_val\n",
        "\n",
        "# Transform the test data\n",
        "X_test[[\"education\"]] = '_______' ## Complete the code to impute missing values in X_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ktryUWkXk87"
      },
      "outputs": [],
      "source": [
        "# Fit and transform the train data\n",
        "X_train[[\"previous_year_rating\", \"avg_training_score\"]] = imputer_median.fit_transform(\n",
        "    X_train[[\"previous_year_rating\", \"avg_training_score\"]]\n",
        ")\n",
        "\n",
        "# Transform the validation data\n",
        "X_val[[\"previous_year_rating\", \"avg_training_score\"]]  =  '_______' ## Complete the code to impute missing values in X_val\n",
        "\n",
        "# Transform the test data\n",
        "X_test[[\"previous_year_rating\", \"avg_training_score\"]] = '_______' ## Complete the code to impute missing values in X_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPyZELz2Xk87"
      },
      "outputs": [],
      "source": [
        "# Checking that no column has missing values in train, validation and test sets\n",
        "print(X_train.isna().sum())\n",
        "print(\"-\" * 30)\n",
        "print(X_val.isna().sum())\n",
        "print(\"-\" * 30)\n",
        "print(X_test.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFeVK4qCXk87"
      },
      "source": [
        "### Encoding categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DFTBhYfXk87"
      },
      "outputs": [],
      "source": [
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "X_val = '_______'  ## Complete the code to impute missing values in X_val\n",
        "X_test = '_______'  ## Complete the code to impute missing values in X_val\n",
        "print(X_train.shape, X_val.shape, X_test.shape)\n",
        "print(X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqf67mrfXk87"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZqmoqz7bp0-"
      },
      "source": [
        "### Model evaluation criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xgSxLRLXk88"
      },
      "source": [
        "**Model can make wrong predictions as:**\n",
        "\n",
        "- Predicting an employee should get promoted when he/she should not get promoted\n",
        "- Predicting an employee should not get promoted when he/she should get promoted\n",
        "\n",
        "**Which case is more important?**\n",
        "\n",
        "- Both cases are important here as not promoting a deserving employee might lead to less productivity and the company might lose a good employee which affects the company's growth. Further, giving promotion to a non-deserving employee would lead to loss of monetary resources and giving such employee higher responsibility might again affect the company's growth.\n",
        "\n",
        "**How to reduce this loss i.e need to reduce False Negatives as well as False Positives?**\n",
        "\n",
        "- Bank would want `F1-score` to be maximized, as both classes are important here. Hence, the focus should be on increasing the F1-score rather than focusing on just one metric i.e. Recall or Precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAhvmbvgXk88"
      },
      "source": [
        "**First, let's create two functions to calculate different metrics and confusion matrix, so that we don't have to use the same code repeatedly for each model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUWFMAI0Xk88"
      },
      "outputs": [],
      "source": [
        "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
        "def model_performance_classification_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    Function to compute different metrics to check classification model performance\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "\n",
        "    # predicting using the independent variables\n",
        "    pred = model.predict(predictors)\n",
        "\n",
        "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
        "    recall = recall_score(target, pred)  # to compute Recall\n",
        "    precision = precision_score(target, pred)  # to compute Precision\n",
        "    f1 = f1_score(target, pred, average=\"macro\")  # to compute F1-score\n",
        "\n",
        "    # creating a dataframe of metrics\n",
        "    df_perf = pd.DataFrame(\n",
        "        {\n",
        "            \"Accuracy\": acc,\n",
        "            \"Recall\": recall,\n",
        "            \"Precision\": precision,\n",
        "            \"F1\": f1,\n",
        "        },\n",
        "        index=[0],\n",
        "    )\n",
        "\n",
        "    return df_perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE6_Z4UmXk88"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix_sklearn(model, predictors, target):\n",
        "    \"\"\"\n",
        "    To plot the confusion_matrix with percentages\n",
        "\n",
        "    model: classifier\n",
        "    predictors: independent variables\n",
        "    target: dependent variable\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(predictors)\n",
        "    cm = confusion_matrix(target, y_pred)\n",
        "    labels = np.asarray(\n",
        "        [\n",
        "            [\"{0:0.0f}\".format(item) + \"\\n{0:.2%}\".format(item / cm.flatten().sum())]\n",
        "            for item in cm.flatten()\n",
        "        ]\n",
        "    ).reshape(2, 2)\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=labels, fmt=\"\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.xlabel(\"Predicted label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdea3372"
      },
      "source": [
        "### Model Building - Original Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = []  # Empty list to store all the models\n",
        "\n",
        "# Appending models into the list\n",
        "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
        "'_______' ## Complete the code to append remaining 4 models in the list models\n",
        "\n",
        "results1 = []  # Empty list to store all model's CV scores\n",
        "names = []  # Empty list to store name of the models\n",
        "\n",
        "\n",
        "# loop through all models to get the mean cross validated score\n",
        "print(\"\\n\" \"Cross-Validation Cost:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=5, shuffle=True, random_state=1\n",
        "    )  # Setting number of splits equal to 5\n",
        "    cv_result = cross_val_score(\n",
        "        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\n",
        "    )\n",
        "    results1.append(cv_result)\n",
        "    names.append(name)\n",
        "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
        "\n",
        "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    scores = recall_score(y_val, model.predict(X_val))\n",
        "    print(\"{}: {}\".format(name, scores))"
      ],
      "metadata": {
        "id": "kh0GkIDCh4aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBqZIXQ5Xk89"
      },
      "outputs": [],
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "\n",
        "fig.suptitle(\"Algorithm Comparison\")\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.boxplot(results1)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6cf8a19"
      },
      "source": [
        "### Model Building - Oversampled Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSOkZv0gXk89"
      },
      "outputs": [],
      "source": [
        "print(\"Before Oversampling, counts of label 'Yes': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before Oversampling, counts of label 'No': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "sm = SMOTE(\n",
        "    sampling_strategy=1, k_neighbors=5, random_state=1\n",
        ")  # Synthetic Minority Over Sampling Technique\n",
        "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"After Oversampling, counts of label 'Yes': {}\".format(sum(y_train_over == 1)))\n",
        "print(\"After Oversampling, counts of label 'No': {} \\n\".format(sum(y_train_over == 0)))\n",
        "\n",
        "\n",
        "print(\"After Oversampling, the shape of train_X: {}\".format(X_train_over.shape))\n",
        "print(\"After Oversampling, the shape of train_y: {} \\n\".format(y_train_over.shape))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsOer36qbp1A"
      },
      "source": [
        "'_______' ## Complete the code to build models on oversampled data\n",
        "## Note - Take reference from the original models built above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwUcBORjbp1A",
        "scrolled": false
      },
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "'_______' ## Write the code to create boxplot to check model performance on oversampled data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62f1f452"
      },
      "source": [
        "### Model Building - Undersampled Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ggUKxVDXk8-"
      },
      "outputs": [],
      "source": [
        "rus = RandomUnderSampler(random_state=1)\n",
        "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7d2hpU6Xk8-"
      },
      "outputs": [],
      "source": [
        "print(\"Before Under Sampling, counts of label 'Yes': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before Under Sampling, counts of label 'No': {} \\n\".format(sum(y_train == 0)))\n",
        "\n",
        "print(\"After Under Sampling, counts of label 'Yes': {}\".format(sum(y_train_un == 1)))\n",
        "print(\"After Under Sampling, counts of label 'No': {} \\n\".format(sum(y_train_un == 0)))\n",
        "\n",
        "print(\"After Under Sampling, the shape of train_X: {}\".format(X_train_un.shape))\n",
        "print(\"After Under Sampling, the shape of train_y: {} \\n\".format(y_train_un.shape))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc5ndPMubp1B",
        "scrolled": true
      },
      "source": [
        "'_______' ## Complete the code to build models on undersampled data\n",
        "## Note - Take reference from the original models built above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HcDqaD2bp1B",
        "scrolled": false
      },
      "source": [
        "# Plotting boxplots for CV scores of all models defined above\n",
        "'_______' ## Write the code to create boxplot to check model performance on undersampled data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLZlKa99bp1C"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Note**\n",
        "1. Sample parameter grid has been provided to do necessary hyperparameter tuning. One can extend/reduce the parameter grid based on execution time and system configuration to try to improve the model performance further wherever needed.      \n",
        "2. The models chosen in this notebook are based on test runs. One can update the best models as obtained upon code execution and tune them for best performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "tFEScXRsl9NM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIKdlCAaz9oG"
      },
      "source": [
        "#### Tuning AdaBoost using Undersampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_I1iVpvoXk9F"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# defining model\n",
        "Model = AdaBoostClassifier(random_state=1)\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": np.arange(10, 110, 10),\n",
        "    \"learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n",
        "    \"base_estimator\": [\n",
        "        DecisionTreeClassifier(max_depth=1, random_state=1),\n",
        "        DecisionTreeClassifier(max_depth=2, random_state=1),\n",
        "        DecisionTreeClassifier(max_depth=3, random_state=1),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = 'f1_macro'\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_jobs = -1, n_iter=50, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.'_______' ## Complete the code to fit the model on undersampled data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJjjnVZvXk9F"
      },
      "outputs": [],
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_adb1 = AdaBoostClassifier( random_state=___,\n",
        "    n_estimators= _______, learning_rate= _______, base_estimator= DecisionTreeClassifier(max_depth=_______, random_state=1)\n",
        ") ## Complete the code with the best parameters obtained from tuning\n",
        "\n",
        "tuned_adb1.'_______' ## Complete the code to fit the model on undersampled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "69JpZdZeQmKY"
      },
      "outputs": [],
      "source": [
        "adb1_train = '_______' ## Complete the code to check the performance on training set\n",
        "adb1_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "h-gj-uBmQmKZ"
      },
      "outputs": [],
      "source": [
        "# Checking model's performance on validation set\n",
        "adb1_val =  '_______' ## Complete the code to check the performance on validation set\n",
        "adb1_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYM4smk5RA6t"
      },
      "source": [
        "#### Tuning AdaBoost using original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDq2B9XJXk9G"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# defining model\n",
        "Model = AdaBoostClassifier(random_state=1)\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": np.arange(10, 110, 10),\n",
        "    \"learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n",
        "    \"base_estimator\": [\n",
        "        DecisionTreeClassifier(max_depth=1, random_state=1),\n",
        "        DecisionTreeClassifier(max_depth=2, random_state=1),\n",
        "        DecisionTreeClassifier(max_depth=3, random_state=1),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = 'f1_macro'\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_jobs = -1, n_iter=50, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.'_______' ## Complete the code to fit the model on original data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qG1EcwH_SdI"
      },
      "outputs": [],
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_adb2 = AdaBoostClassifier( random_state=___,\n",
        "    n_estimators= _______, learning_rate= _______, base_estimator= DecisionTreeClassifier(max_depth=_______, random_state=1)\n",
        ") ## Complete the code with the best parameters obtained from tuning\n",
        "\n",
        "tuned_adb2.'_______' ## Complete the code to fit the model on original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "NVyTtWmjSNC4"
      },
      "outputs": [],
      "source": [
        "adb2_train = '_______' ## Complete the code to check the performance on training set\n",
        "adb2_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "-61CMbHbSNC4"
      },
      "outputs": [],
      "source": [
        "# Checking model's performance on validation set\n",
        "adb2_val =  '_______' ## Complete the code to check the performance on validation set\n",
        "adb2_val"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tuning Gradient Boosting using undersampled data"
      ],
      "metadata": {
        "id": "XoLT8ewJ5V2d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP9sq82oXk9H"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "#Creating pipeline\n",
        "Model = GradientBoostingClassifier(random_state=1)\n",
        "\n",
        "#Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"init\": [AdaBoostClassifier(random_state=1),DecisionTreeClassifier(random_state=1)],\n",
        "    \"n_estimators\": np.arange(75,150,25),\n",
        "    \"learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n",
        "    \"subsample\":[0.5,0.7,1],\n",
        "    \"max_features\":[0.5,0.7,1],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = 'f1_macro'\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, scoring=scorer, cv=5, random_state=1, n_jobs = -1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.'_______' ## Complete the code to fit the model on under sampled data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_gbm1 = GradientBoostingClassifier(\n",
        "    max_features=_______,\n",
        "    init=AdaBoostClassifier(random_state=1),\n",
        "    random_state=1,\n",
        "    learning_rate=_______,\n",
        "    n_estimators=_______,\n",
        "    subsample=_______,\n",
        ")## Complete the code with the best parameters obtained from tuning\n",
        "\n",
        "tuned_gbm1.fit(X_train_un, y_train_un)"
      ],
      "metadata": {
        "id": "j_61Omhq5KkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbm1_train = '_______' ## Complete the code to check the performance on oversampled train set\n",
        "gbm1_train"
      ],
      "metadata": {
        "id": "k8Oxv7PIJTmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbm1_val = '_______' ## Complete the code to check the performance on validation set\n",
        "gbm1_val"
      ],
      "metadata": {
        "id": "wpcbbrBLJjS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tuning Gradient Boosting using original data"
      ],
      "metadata": {
        "id": "X0fOfEEdBXay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-SQ5l_AXk9I"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "#defining model\n",
        "Model = GradientBoostingClassifier(random_state=1)\n",
        "\n",
        "#Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"init\": [AdaBoostClassifier(random_state=1),DecisionTreeClassifier(random_state=1)],\n",
        "    \"n_estimators\": np.arange(75,150,25),\n",
        "    \"learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n",
        "    \"subsample\":[0.5,0.7,1],\n",
        "    \"max_features\":[0.5,0.7,1],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = 'f1_macro'\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=50, scoring=scorer, cv=5, random_state=1, n_jobs = -1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv.'_______' ## Complete the code to fit the model on original data\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new pipeline with best parameters\n",
        "tuned_gbm2 = GradientBoostingClassifier(\n",
        "    max_features=_______,\n",
        "    init=AdaBoostClassifier(random_state=1),\n",
        "    random_state=1,\n",
        "    learning_rate=_______,\n",
        "    n_estimators=_______,\n",
        "    subsample=_______,\n",
        ")## Complete the code with the best parameters obtained from tuning\n",
        "\n",
        "tuned_gbm2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2YlugBs8Bewz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbm2_train = '_______' ## Complete the code to check the performance on original data\n",
        "gbm2_train"
      ],
      "metadata": {
        "id": "ilYVyajmBew0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbm2_val = '_______' ## Complete the code to check the performance on validation set\n",
        "gbm2_val"
      ],
      "metadata": {
        "id": "ptkIcRnjBew0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9JNnpxa4jau"
      },
      "source": [
        "## Model Comparison and Final Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOs9oFzCXk9J"
      },
      "outputs": [],
      "source": [
        "# training performance comparison\n",
        "\n",
        "models_train_comp_df = pd.concat(\n",
        "    [\n",
        "        gbm1_train.T,\n",
        "        gbm2_train.T,\n",
        "        adb1_train.T,\n",
        "        adb2_train.T,\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "models_train_comp_df.columns = [\n",
        "    \"Gradient boosting trained with Undersampled data\",\n",
        "    \"Gradient boosting trained with Original data\",\n",
        "    \"AdaBoost trained with Undersampled data\",\n",
        "    \"AdaBoost trained with Original data\",\n",
        "]\n",
        "print(\"Training performance comparison:\")\n",
        "models_train_comp_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FgTXpsXbp1F"
      },
      "source": [
        "# validation performance comparison\n",
        "\n",
        "'_______' ## Write the code to compare the performance on validation set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYS5m_mcbp1F"
      },
      "source": [
        "**Now we have our final model, so let's find out how our final model is performing on unseen test data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqgvz7e7bp1F"
      },
      "source": [
        "# Let's check the performance on test set\n",
        "'_______' ## Write the code to check the performance of best model on test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Importances"
      ],
      "metadata": {
        "id": "J49s-TEB41JQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zk2dFRzbp1F"
      },
      "source": [
        "feature_names = X_train.columns\n",
        "importances =  '_______' ## Complete the code to check the feature importance of the best model\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel(\"Relative Importance\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxFmwam_bp1M"
      },
      "source": [
        "# Business Insights and Conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-\n"
      ],
      "metadata": {
        "id": "RZN2YkUhq77C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***"
      ],
      "metadata": {
        "id": "MyLBn7uE6LhP"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xxhpZv9y-qTw",
        "M1TEog7cAs5m",
        "Ch_TjRfF-qT5",
        "nUCorhch-qT4",
        "DhPuzWO7hmV8",
        "-YyWJgFlKlWM",
        "kMZ-iAFSvY3s",
        "0RJVJyMaXk8u",
        "0svWVo63Xk8v",
        "IQqeDcohXk8v",
        "K-1GJtmpXk8w",
        "9bEfcnKyXk8w",
        "vsMA-L_SXk8x",
        "MCI5jLAyXk8x",
        "375LIJSqXk8x",
        "Fi2h9-R_Xk8y",
        "cw6XLeL1Xk8y",
        "Eo_TjLtrXk8z",
        "G-Og-a_qXk8z",
        "xaPBvS4FXk80",
        "YlAnw_xDXk81",
        "0Ruq7LujXk81",
        "ejNtzzp-Xk82",
        "SBq-u2UfXk82",
        "Qyj-sWOgXk83",
        "qEMG1_lkXk83",
        "pvfrLMXYXk84",
        "nhMfzOGkXk84",
        "H3V9J6ueXk84",
        "C16v3j98Xk85",
        "QHo0SRqVp9yG",
        "rAiIh-pRqcIt",
        "081ec1f8",
        "NFeVK4qCXk87",
        "iqf67mrfXk87",
        "YZqmoqz7bp0-",
        "cdea3372",
        "d6cf8a19",
        "62f1f452",
        "zLZlKa99bp1C",
        "D9JNnpxa4jau",
        "gxFmwam_bp1M"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}